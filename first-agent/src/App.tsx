import { useState, useEffect } from 'react';
import './App.css';
import { connectSession, setMessageCallback } from './agent';
import ConnectionView from './components/ConnectionView';
import ConversationView from './components/ConversationView';
import DebugPanel from './components/DebugPanel';
import TestControls from './components/TestControls';

interface Message {
  role: 'user' | 'assistant';
  content: string;
  timestamp: Date;
  isStreaming?: boolean;
  messageId?: string;
}

function App() {
  const [isConnected, setIsConnected] = useState(false);
  const [apiKey, setApiKey] = useState('');
  const [messages, setMessages] = useState<Message[]>([]);
  const [isListening, setIsListening] = useState(false);
  const [debugInfo, setDebugInfo] = useState<string[]>([]);

  const addDebugInfo = (info: string) => {
    console.log('Debug:', info);
    setDebugInfo(prev => [...prev.slice(-9), `${new Date().toLocaleTimeString()}: ${info}`]);
  };

  useEffect(() => {
    setMessageCallback((message: Message, messageId?: string) => {
      console.log('Message received:', message, 'ID:', messageId);
      
      setMessages(prev => {
        if (messageId && message.isStreaming) {
          const existingIndex = prev.findIndex(m => m.messageId === messageId);
          if (existingIndex !== -1) {
            const newMessages = [...prev];
            newMessages[existingIndex] = { ...message, messageId };
            return newMessages;
          } else {
            return [...prev, { ...message, messageId }];
          }
        } else {
          const finalMessage = { ...message, messageId: messageId || `${message.role}-${Date.now()}`, isStreaming: false };
          
          if (messageId) {
            const existingIndex = prev.findIndex(m => m.messageId === messageId);
            if (existingIndex !== -1) {
              const newMessages = [...prev];
              newMessages[existingIndex] = finalMessage;
              return newMessages;
            }
          }
          
          return [...prev, finalMessage];
        }
      });
      
      addDebugInfo(`æ–°æ¶ˆæ¯: ${message.role} - ${message.content.substring(0, 50)}... (${message.isStreaming ? 'æµå¼ä¸­' : 'å®Œæˆ'})`);
    });
  }, []);

  const handleConnect = async () => {
    if (!apiKey) {
      alert('Please enter your OpenAI API key');
      return;
    }
    
    try {
      setMessages([]);
      addDebugInfo('é–‹å§‹é€£æŽ¥...');
      
      await connectSession(apiKey);
      setIsConnected(true);
      setIsListening(true);
      addDebugInfo('é€£æŽ¥æˆåŠŸï¼');
      
      setMessages([{
        role: 'assistant',
        content: 'ðŸ”— å·²é€£æŽ¥åˆ°èªžéŸ³åŠ©æ‰‹ï¼è«‹é–‹å§‹èªªè©±...',
        timestamp: new Date()
      }]);
      
    } catch (error) {
      console.error('Connection error:', error);
      if (error instanceof Error) {
        addDebugInfo(`é€£æŽ¥éŒ¯èª¤: ${error.message}`);
      } else {
        addDebugInfo(`é€£æŽ¥éŒ¯èª¤: ${String(error)}`);
      }
      alert('Failed to connect. Please check your API key and try again.');
    }
  };

  const testAIResponse = () => {
    const testResponses = [
      'ä½ å¥½ï¼æˆ‘æ˜¯ AI åŠ©æ‰‹ï¼Œå¾ˆé«˜èˆˆç‚ºæ‚¨æœå‹™ã€‚',
      'æˆ‘å¯ä»¥å¹«åŠ©æ‚¨å›žç­”å•é¡Œå’Œé€²è¡Œå°è©±ã€‚',
      'è«‹å•æœ‰ä»€éº¼æˆ‘å¯ä»¥å”åŠ©æ‚¨çš„å—Žï¼Ÿ',
      'æ‚¨çš„ä¸­æ–‡èªªå¾—å¾ˆå¥½ï¼',
      'ä»Šå¤©å¤©æ°£çœŸä¸éŒ¯ï¼Œé©åˆå‡ºé–€èµ°èµ°ã€‚'
    ];
    
    const randomResponse = testResponses[Math.floor(Math.random() * testResponses.length)];
    
    setMessages(prev => [...prev, {
      role: 'assistant',
      content: randomResponse,
      timestamp: new Date()
    }]);
    
    addDebugInfo(`æ¸¬è©¦ AI å›žæ‡‰: ${randomResponse}`);
  };

  const testVoiceRecognition = async () => {
    addDebugInfo('é–‹å§‹æ‰‹å‹•èªžéŸ³æ¸¬è©¦...');
    
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      addDebugInfo('âœ… éº¥å…‹é¢¨æ¬Šé™å·²ç²å¾—');
      
      if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
        const SpeechRecognition = (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition;
        const recognition = new SpeechRecognition();
        
        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.lang = 'zh-CN';
        
        recognition.onresult = (event: any) => {
          const transcript = event.results[event.results.length - 1][0].transcript;
          addDebugInfo(`èªžéŸ³è­˜åˆ¥çµæžœ: ${transcript}`);
          setMessages(prev => [...prev, {
            role: 'user',
            content: transcript,
            timestamp: new Date()
          }]);
        };
        
        recognition.onerror = (event: any) => {
          addDebugInfo(`èªžéŸ³è­˜åˆ¥éŒ¯èª¤: ${event.error}`);
        };
        
        recognition.start();
        addDebugInfo('âœ… ç€è¦½å™¨èªžéŸ³è­˜åˆ¥å·²å•Ÿå‹•');
        
        setTimeout(() => {
          recognition.stop();
          addDebugInfo('èªžéŸ³è­˜åˆ¥å·²åœæ­¢');
        }, 10000);
        
      } else {
        addDebugInfo('âŒ ç€è¦½å™¨ä¸æ”¯æŒèªžéŸ³è­˜åˆ¥');
      }
      
      stream.getTracks().forEach(track => track.stop());
      
    } catch (error) {
      addDebugInfo(`éº¥å…‹é¢¨æ¸¬è©¦å¤±æ•—: ${error}`);
    }
  };

  return (
    <>
      <h1>OpenAI Realtime Agent</h1>
      
      <div className="card">
        {!isConnected ? (
          <ConnectionView
            apiKey={apiKey}
            setApiKey={setApiKey}
            handleConnect={handleConnect}
          />
        ) : (
          <div>
            <h2>ðŸŽ¤ Voice Assistant Connected!</h2>
            <p>You can now start talking to your assistant.</p>
            <p>Grant microphone access when prompted.</p>
            
            <ConversationView messages={messages} />
            
            <div className="listening-indicator">
              <div className={`status-dot ${isListening ? 'listening' : ''}`}></div>
              <span style={{ color: isListening ? '#4CAF50' : '#666' }}>
                {isListening ? 'ðŸŽ¤ Listening...' : 'ðŸ”‡ Not listening'}
              </span>
            </div>
            
            <TestControls
              testAIResponse={testAIResponse}
              testVoiceRecognition={testVoiceRecognition}
            />
            
            <DebugPanel debugInfo={debugInfo} />
          </div>
        )}
      </div>
      
      <p className="read-the-docs">
        Connect your OpenAI API key and start voice chatting!
      </p>
    </>
  );
}

export default App;