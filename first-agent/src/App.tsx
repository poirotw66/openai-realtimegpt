import { useState, useEffect, useRef } from 'react';
import './App.css';
import { connectSession, disconnectSession, pauseSession, getSupportsPause, setMessageCallback, sendAudioFromFile, flushUserMessagesFromSession } from './agent';
import ConnectionView from './components/ConnectionView';
import ConversationView from './components/ConversationView';

interface Message {
  role: 'user' | 'assistant';
  content: string;
  timestamp: Date;
  isStreaming?: boolean;
  messageId?: string;
}

function App() {
  const [isConnected, setIsConnected] = useState(false);
  const [hasEnteredConversation, setHasEnteredConversation] = useState(false);
  const [messages, setMessages] = useState<Message[]>([]);
  const [isListening, setIsListening] = useState(false);
  const [isPaused, setIsPaused] = useState(false);
  const [supportsPause, setSupportsPause] = useState(false);
  const [testAudioSending, setTestAudioSending] = useState(false);
  const testAudioInputRef = useRef<HTMLInputElement>(null);

  useEffect(() => {
    setMessageCallback((message: Message, messageId?: string) => {
      // Hide initial greeting trigger (single dot sent to make model say hello)
      if (message.role === 'user' && message.content.trim() === '.') return;
      
      setMessages(prev => {
        if (messageId && message.isStreaming) {
          const existingIndex = prev.findIndex(m => m.messageId === messageId);
          if (existingIndex !== -1) {
            const newMessages = [...prev];
            newMessages[existingIndex] = { ...message, messageId };
            return newMessages;
          } else {
            return [...prev, { ...message, messageId }];
          }
        } else {
          const finalMessage = { ...message, messageId: messageId || `${message.role}-${Date.now()}`, isStreaming: false };
          
          if (messageId) {
            const existingIndex = prev.findIndex(m => m.messageId === messageId);
            if (existingIndex !== -1) {
              const newMessages = [...prev];
              newMessages[existingIndex] = finalMessage;
              return newMessages;
            }
          }
          
          return [...prev, finalMessage];
        }
      });
      
    });
  }, []);

  const handleConnect = async () => {
    try {
      if (!hasEnteredConversation) {
        setMessages([]);
      }
      
      await connectSession();
      setIsConnected(true);
      setIsListening(true);
      setHasEnteredConversation(true);
      
      setMessages((prev) => {
        if (prev.length === 0) {
          return [{
            role: 'assistant',
            content: 'ğŸ”— å·²é€£æ¥åˆ°èªéŸ³åŠ©æ‰‹ï¼è«‹é–‹å§‹èªªè©±...',
            timestamp: new Date()
          }];
        }
        return prev;
      });
      
    } catch (error) {
      console.error('Connection error:', error);
      alert('Failed to connect. Ensure MCP proxy is running (npm run dev-full) and OPENAI_API_KEY is set in .env');
    }
  };

  const handleDisconnect = () => {
    disconnectSession();
    setIsConnected(false);
    setIsListening(false);
    setIsPaused(false);
    setSupportsPause(false);
  };

  const handlePauseToggle = () => {
    if (!supportsPause) return;
    const nextPaused = !isPaused;
    pauseSession(nextPaused);
    setIsPaused(nextPaused);
  };

  const handleSendTestAudio = async () => {
    const file = testAudioInputRef.current?.files?.[0];
    if (!file) {
      alert('è«‹å…ˆé¸æ“‡ä¸€å€‹éŸ³æª”ï¼ˆWAVã€MP3 ç­‰ï¼‰');
      return;
    }
    try {
      setTestAudioSending(true);
      await sendAudioFromFile(file);
      
      // Simple retry mechanism for transcription
      setTimeout(() => flushUserMessagesFromSession(), 1000);
      setTimeout(() => flushUserMessagesFromSession(), 3000);
    } catch (err) {
      const msg = err instanceof Error ? err.message : String(err);
      alert(`å‚³é€å¤±æ•—: ${msg}`);
    } finally {
      setTestAudioSending(false);
      if (testAudioInputRef.current) testAudioInputRef.current.value = '';
    }
  };

  const debugSessionHistory = () => {
    flushUserMessagesFromSession();
  };

  const testAIResponse = () => {
    const testResponses = [
      'ä½ å¥½ï¼æˆ‘æ˜¯ AI åŠ©æ‰‹ï¼Œå¾ˆé«˜èˆˆç‚ºæ‚¨æœå‹™ã€‚',
      'æˆ‘å¯ä»¥å¹«åŠ©æ‚¨å›ç­”å•é¡Œå’Œé€²è¡Œå°è©±ã€‚',
      'è«‹å•æœ‰ä»€éº¼æˆ‘å¯ä»¥å”åŠ©æ‚¨çš„å—ï¼Ÿ',
      'æ‚¨çš„ä¸­æ–‡èªªå¾—å¾ˆå¥½ï¼',
      'ä»Šå¤©å¤©æ°£çœŸä¸éŒ¯ï¼Œé©åˆå‡ºé–€èµ°èµ°ã€‚'
    ];
    
    const randomResponse = testResponses[Math.floor(Math.random() * testResponses.length)];
    
    setMessages(prev => [...prev, {
      role: 'assistant',
      content: randomResponse,
      timestamp: new Date()
    }]);
  };

  const testVoiceRecognition = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      
      if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
        const SpeechRecognition = (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition;
        const recognition = new SpeechRecognition();
        
        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.lang = 'zh-CN';
        
        recognition.onresult = (event: any) => {
          const transcript = event.results[event.results.length - 1][0].transcript;
          setMessages(prev => [...prev, {
            role: 'user',
            content: transcript,
            timestamp: new Date()
          }]);
        };
        
        recognition.start();
        
        setTimeout(() => {
          recognition.stop();
        }, 10000);
        
      }
      
      stream.getTracks().forEach(track => track.stop());
      
    } catch (error) {
      console.error('Voice test failed:', error);
    }
  };

  return (
    <>
      <h1>OpenAI Realtime Agent</h1>
      
      <div className="card">
        {!hasEnteredConversation ? (
          <ConnectionView handleConnect={handleConnect} />
        ) : (
          <div className="connected-view">
            <div className="connection-bar">
              <div className="listening-indicator">
                <div className={`status-dot ${isListening ? 'listening' : ''}`} />
                <span className={isListening ? 'listening-text' : ''}>
                  {isConnected ? (isPaused ? 'â¸ å·²æš«åœ' : isListening ? 'ğŸ¤ è†è½ä¸­â€¦' : 'ğŸ”‡ æœªè†è½') : 'å·²æ›æ–·'}
                </span>
              </div>
              {isConnected ? (
                <>
                  {supportsPause && (
                    <button type="button" className="btn-pause" onClick={handlePauseToggle}>
                      {isPaused ? 'ç¹¼çºŒ' : 'æš«åœ'}
                    </button>
                  )}
                  <button type="button" className="btn-disconnect" onClick={handleDisconnect}>
                    æ›æ–·
                  </button>
                </>
              ) : (
                <button type="button" className="btn-connect" onClick={handleConnect}>
                  é–‹å§‹é€£ç·š
                </button>
              )}
            </div>
            <p className="connected-hint">
              {isConnected
                ? 'å¯ç›´æ¥å°éº¥å…‹é¢¨èªªè©±ï¼Œæˆ–ä½¿ç”¨ä¸‹æ–¹ã€Œæ¸¬è©¦éŸ³æª”ã€ä¸Šå‚³éŸ³æª”æ¨¡æ“¬èªéŸ³è¼¸å…¥ã€‚'
                : 'é»ã€Œé–‹å§‹é€£ç·šã€é‡æ–°é€£æ¥ï¼Œå°è©±è¨˜éŒ„æœƒä¿ç•™ã€‚'}
            </p>
            <div className="test-audio-section" style={{ opacity: isConnected ? 1 : 0.6 }}>
              <label className="test-audio-label">
                <span>ä½¿ç”¨æ¸¬è©¦éŸ³æª”ï¼š</span>
                <input
                  ref={testAudioInputRef}
                  type="file"
                  accept="audio/*"
                  className="test-audio-input"
                  disabled={testAudioSending || !isConnected}
                />
              </label>
              <button
                type="button"
                className="btn-send-test-audio"
                onClick={handleSendTestAudio}
                disabled={testAudioSending || !isConnected}
              >
                {testAudioSending ? 'å‚³é€ä¸­â€¦' : 'å‚³é€æ¸¬è©¦éŸ³æª”'}
              </button>
            </div>
            <ConversationView messages={messages} />
          </div>
        )}
      </div>
      
      <p className="read-the-docs">
        é»ã€ŒConnect to Voice Assistantã€é–‹å§‹é€£ç·šï¼›é€£ç·šå¾Œå¯ç›´æ¥èªªè©±ï¼Œå¯é»ã€Œæš«åœã€æš«åœæ”¶ç™¼èªéŸ³ï¼ˆå†é»ã€Œç¹¼çºŒã€æ¢å¾©ï¼‰ï¼Œæˆ–é»ã€Œæ›æ–·ã€çµæŸé€£ç·šã€‚
      </p>
    </>
  );
}

export default App;