import { useState, useEffect, useRef } from 'react';
import './App.css';
import { connectSession, disconnectSession, pauseSession, getSupportsPause, setMessageCallback, sendAudioFromFile, flushUserMessagesFromSession } from './agent';
import WelcomePage from './components/WelcomePage';
import ModelSelection from './components/ModelSelection';
import ConversationView from './components/ConversationView';

interface Message {
  role: 'user' | 'assistant';
  content: string;
  timestamp: Date;
  isStreaming?: boolean;
  messageId?: string;
}

type AppView = 'welcome' | 'model-selection' | 'connecting' | 'chat';
type SelectedModel = 'gpt-realtime' | 'gemini-live' | null;

function App() {
  const [currentView, setCurrentView] = useState<AppView>('welcome');
  const [selectedModel, setSelectedModel] = useState<SelectedModel>(null);
  const [isConnected, setIsConnected] = useState(false);
  const [messages, setMessages] = useState<Message[]>([]);
  const [isListening, setIsListening] = useState(false);
  const [isPaused, setIsPaused] = useState(false);
  const [supportsPause, setSupportsPause] = useState(false);
  const [testAudioSending, setTestAudioSending] = useState(false);
  const [isConnecting, setIsConnecting] = useState(false);
  const testAudioInputRef = useRef<HTMLInputElement>(null);

  useEffect(() => {
    setMessageCallback((message: Message, messageId?: string) => {
      // Hide initial greeting trigger (single dot sent to make model say hello)
      if (message.role === 'user' && message.content.trim() === '.') return;
      
      setMessages(prev => {
        const id = messageId || `${message.role}-${Date.now()}`;
        
        // For streaming messages, update existing or add new
        if (message.isStreaming) {
          const existingIndex = prev.findIndex(m => m.messageId === id);
          if (existingIndex !== -1) {
            const newMessages = [...prev];
            newMessages[existingIndex] = { ...message, messageId: id };
            return newMessages;
          } else {
            return [...prev, { ...message, messageId: id }];
          }
        } 
        // For final messages, always update existing or add new
        else {
          const existingIndex = prev.findIndex(m => m.messageId === id);
          if (existingIndex !== -1) {
            // Update existing message with final content
            const newMessages = [...prev];
            newMessages[existingIndex] = { ...message, messageId: id, isStreaming: false };
            return newMessages;
          } else {
            // Add new final message only if no existing message with same ID
            return [...prev, { ...message, messageId: id, isStreaming: false }];
          }
        }
      });
    });
  }, []);

  const handleStartChat = () => {
    setCurrentView('model-selection');
  };

  const handleSelectModel = (model: 'gpt-realtime' | 'gemini-live') => {
    if (model === 'gemini-live') {
      alert('Gemini Live åŠŸèƒ½å³å°‡æ¨å‡ºï¼Œè«‹é¸æ“‡ GPT Realtime');
      return;
    }
    
    setSelectedModel(model);
    setCurrentView('connecting');
    handleConnect();
  };

  const handleBackToWelcome = () => {
    setCurrentView('welcome');
    setSelectedModel(null);
  };

  const handleBackToModelSelection = () => {
    setCurrentView('model-selection');
    handleDisconnect();
  };

  const handleConnect = async () => {
    try {
      setIsConnecting(true);
      setMessages([]);
      
      await connectSession();
      setIsConnected(true);
      setIsListening(true);
      setCurrentView('chat');
      
      setMessages([{
        role: 'assistant',
        content: 'ğŸ”— å·²é€£æ¥åˆ° GPT Realtimeï¼è«‹é–‹å§‹èªªè©±...',
        timestamp: new Date()
      }]);
      
    } catch (error) {
      console.error('Connection error:', error);
      alert('é€£æ¥å¤±æ•—ã€‚è«‹ç¢ºä¿ MCP proxy æ­£åœ¨é‹è¡Œ (npm run dev-full) ä¸” .env ä¸­å·²è¨­å®š OPENAI_API_KEY');
      setCurrentView('model-selection');
    } finally {
      setIsConnecting(false);
    }
  };

  const handleDisconnect = () => {
    disconnectSession();
    setIsConnected(false);
    setIsListening(false);
    setIsPaused(false);
    setSupportsPause(false);
    setCurrentView('model-selection');
  };

  const handlePauseToggle = () => {
    if (!supportsPause) return;
    const nextPaused = !isPaused;
    pauseSession(nextPaused);
    setIsPaused(nextPaused);
  };

  const handleSendTestAudio = async () => {
    const file = testAudioInputRef.current?.files?.[0];
    if (!file) {
      alert('è«‹å…ˆé¸æ“‡ä¸€å€‹éŸ³æª”ï¼ˆWAVã€MP3 ç­‰ï¼‰');
      return;
    }
    try {
      setTestAudioSending(true);
      await sendAudioFromFile(file);
      
      // Simple retry mechanism for transcription
      setTimeout(() => flushUserMessagesFromSession(), 1000);
      setTimeout(() => flushUserMessagesFromSession(), 3000);
    } catch (err) {
      const msg = err instanceof Error ? err.message : String(err);
      alert(`å‚³é€å¤±æ•—: ${msg}`);
    } finally {
      setTestAudioSending(false);
      if (testAudioInputRef.current) testAudioInputRef.current.value = '';
    }
  };

  const debugSessionHistory = () => {
    flushUserMessagesFromSession();
  };

  const testAIResponse = () => {
    const testResponses = [
      'ä½ å¥½ï¼æˆ‘æ˜¯ AI åŠ©æ‰‹ï¼Œå¾ˆé«˜èˆˆç‚ºæ‚¨æœå‹™ã€‚',
      'æˆ‘å¯ä»¥å¹«åŠ©æ‚¨å›ç­”å•é¡Œå’Œé€²è¡Œå°è©±ã€‚',
      'è«‹å•æœ‰ä»€éº¼æˆ‘å¯ä»¥å”åŠ©æ‚¨çš„å—ï¼Ÿ',
      'æ‚¨çš„ä¸­æ–‡èªªå¾—å¾ˆå¥½ï¼',
      'ä»Šå¤©å¤©æ°£çœŸä¸éŒ¯ï¼Œé©åˆå‡ºé–€èµ°èµ°ã€‚'
    ];
    
    const randomResponse = testResponses[Math.floor(Math.random() * testResponses.length)];
    
    setMessages(prev => [...prev, {
      role: 'assistant',
      content: randomResponse,
      timestamp: new Date()
    }]);
  };

  const testVoiceRecognition = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      
      if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
        const SpeechRecognition = (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition;
        const recognition = new SpeechRecognition();
        
        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.lang = 'zh-CN';
        
        recognition.onresult = (event: any) => {
          const transcript = event.results[event.results.length - 1][0].transcript;
          setMessages(prev => [...prev, {
            role: 'user',
            content: transcript,
            timestamp: new Date()
          }]);
        };
        
        recognition.start();
        
        setTimeout(() => {
          recognition.stop();
        }, 10000);
        
      }
      
      stream.getTracks().forEach(track => track.stop());
      
    } catch (error) {
      console.error('Voice test failed:', error);
    }
  };

  const renderCurrentView = () => {
    switch (currentView) {
      case 'welcome':
        return <WelcomePage onStartChat={handleStartChat} />;
      
      case 'model-selection':
        return (
          <ModelSelection 
            onSelectModel={handleSelectModel} 
            onBack={handleBackToWelcome}
          />
        );
      
      case 'connecting':
        return (
          <div className="connecting-view">
            <div className="connecting-container">
              <div className="loading-spinner"></div>
              <h2>é€£æ¥ä¸­...</h2>
              <p>æ­£åœ¨å»ºç«‹èˆ‡ {selectedModel === 'gpt-realtime' ? 'GPT Realtime' : 'Gemini Live'} çš„é€£æ¥</p>
            </div>
          </div>
        );
      
      case 'chat':
        return (
          <div className="chat-view">
            <div className="chat-header">
              <button className="back-btn" onClick={handleBackToModelSelection}>
                â† é¸æ“‡å…¶ä»–æ¨¡å‹
              </button>
              <div className="chat-title">
                <span className="model-name">{selectedModel === 'gpt-realtime' ? 'GPT Realtime' : 'Gemini Live'}</span>
                <div className="connection-status">
                  <div className={`status-dot ${isListening ? 'listening' : ''}`} />
                  <span className={isListening ? 'listening-text' : ''}>
                    {isConnected ? (isPaused ? 'â¸ å·²æš«åœ' : isListening ? 'ğŸ¤ è†è½ä¸­â€¦' : 'ğŸ”‡ æœªè†è½') : 'å·²æ›æ–·'}
                  </span>
                </div>
              </div>
              <div className="chat-controls">
                {isConnected && supportsPause && (
                  <button type="button" className="btn-pause" onClick={handlePauseToggle}>
                    {isPaused ? 'ç¹¼çºŒ' : 'æš«åœ'}
                  </button>
                )}
                {isConnected && (
                  <button type="button" className="btn-disconnect" onClick={handleDisconnect}>
                    æ›æ–·
                  </button>
                )}
              </div>
            </div>
            
            <div className="chat-content">
              <ConversationView messages={messages} />
            </div>
            
            <div className="chat-footer">
              <div className="test-audio-section">
                <label className="test-audio-label">
                  <span>æ¸¬è©¦éŸ³æª”ï¼š</span>
                  <input
                    ref={testAudioInputRef}
                    type="file"
                    accept="audio/*"
                    className="test-audio-input"
                    disabled={testAudioSending || !isConnected}
                  />
                </label>
                <button
                  type="button"
                  className="btn-send-test-audio"
                  onClick={handleSendTestAudio}
                  disabled={testAudioSending || !isConnected}
                >
                  {testAudioSending ? 'å‚³é€ä¸­â€¦' : 'å‚³é€'}
                </button>
              </div>
              <p className="chat-hint">
                {isConnected
                  ? 'å¯ç›´æ¥å°éº¥å…‹é¢¨èªªè©±ï¼Œæˆ–ä½¿ç”¨ä¸Šæ–¹ã€Œæ¸¬è©¦éŸ³æª”ã€ä¸Šå‚³éŸ³æª”ã€‚'
                  : 'é€£æ¥å·²ä¸­æ–·'}
              </p>
            </div>
          </div>
        );
      
      default:
        return <WelcomePage onStartChat={handleStartChat} />;
    }
  };

  return (
    <div className="app">
      {renderCurrentView()}
    </div>
  );
}

export default App;